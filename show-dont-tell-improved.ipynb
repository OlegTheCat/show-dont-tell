{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tell    922\n",
       "show    405\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "oleh_dataset = pd.read_csv('dataset.csv')\n",
    "oleh_dataset = oleh_dataset[oleh_dataset['label'] != 'unknown']\n",
    "oleh_dataset['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "show    40\n",
       "tell    26\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('show-validation.txt', 'r') as f:\n",
    "    show_sents = f.readlines()\n",
    "    \n",
    "with open('tell-validation.txt', 'r') as f:\n",
    "    tell_sents = f.readlines()\n",
    "    \n",
    "scraped_dataset = pd.DataFrame({'sentence': show_sents + tell_sents,\n",
    "                                'label': ['show'] * len(show_sents) + ['tell'] * len(tell_sents)})\n",
    "\n",
    "scraped_dataset['sentence'] = scraped_dataset['sentence'].str.strip()\n",
    "\n",
    "scraped_dataset['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tell    118\n",
       "show     15\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('katia-show.txt', 'r') as f:\n",
    "    show_sents = f.readlines()\n",
    "    \n",
    "with open('katia-tell.txt', 'r') as f:\n",
    "    tell_sents = f.readlines()\n",
    "\n",
    "katia_dataset = pd.DataFrame({'sentence': show_sents + tell_sents,\n",
    "                              'label': ['show'] * len(show_sents) + ['tell'] * len(tell_sents)})\n",
    "\n",
    "katia_dataset['sentence'] = katia_dataset['sentence'].str.strip()\n",
    "\n",
    "katia_dataset['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Катя надіслала розмічені речення, тому перерахую бейзлайн"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "oleh_dataset['sentence'] = oleh_dataset['sentence'].apply(nlp)\n",
    "scraped_dataset['sentence'] = scraped_dataset['sentence'].apply(nlp)\n",
    "katia_dataset['sentence'] = katia_dataset['sentence'].apply(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_oleh_train, X_oleh_test, y_oleh_train, y_oleh_test = train_test_split(oleh_dataset['sentence'], oleh_dataset['label'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def tokenize(model):\n",
    "    return [tok.text for tok in model]\n",
    "\n",
    "def lemmatize(model):\n",
    "    return [tok.lemma_ for tok in model]\n",
    "\n",
    "def make_baseline_clf():\n",
    "    return Pipeline([('vect', CountVectorizer(lowercase=False, token_pattern=None)),\n",
    "                     ('nb', MultinomialNB()),\n",
    "                    ])\n",
    "\n",
    "def validation_report(clf):\n",
    "    print('Oleh:')\n",
    "    print(classification_report(y_oleh_test, clf.predict(X_oleh_test)))\n",
    "    print('')\n",
    "    print('')\n",
    "    print('')\n",
    "    print('Scraped:')\n",
    "    print(classification_report(scraped_dataset['label'], clf.predict(scraped_dataset['sentence'])))\n",
    "    print('')\n",
    "    print('')\n",
    "    print('')\n",
    "    print('Katia:')\n",
    "    print(classification_report(katia_dataset['label'], clf.predict(katia_dataset['sentence'])))\n",
    "    print('')\n",
    "    print('')\n",
    "    print('')\n",
    "    print('All:')\n",
    "    print(classification_report(pd.concat([y_oleh_test, scraped_dataset['label'], katia_dataset['label']]), \n",
    "                                clf.predict(pd.concat([X_oleh_test, scraped_dataset['sentence'], katia_dataset['sentence']]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oleh:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       0.74      0.35      0.48       110\n",
      "        tell       0.75      0.94      0.83       222\n",
      "\n",
      "    accuracy                           0.74       332\n",
      "   macro avg       0.74      0.65      0.65       332\n",
      "weighted avg       0.74      0.74      0.71       332\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Scraped:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       0.75      0.15      0.25        40\n",
      "        tell       0.41      0.92      0.57        26\n",
      "\n",
      "    accuracy                           0.45        66\n",
      "   macro avg       0.58      0.54      0.41        66\n",
      "weighted avg       0.62      0.45      0.38        66\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Katia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       0.11      0.13      0.12        15\n",
      "        tell       0.89      0.86      0.88       118\n",
      "\n",
      "    accuracy                           0.78       133\n",
      "   macro avg       0.50      0.50      0.50       133\n",
      "weighted avg       0.80      0.78      0.79       133\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "All:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       0.59      0.28      0.39       165\n",
      "        tell       0.74      0.91      0.82       366\n",
      "\n",
      "    accuracy                           0.72       531\n",
      "   macro avg       0.67      0.60      0.60       531\n",
      "weighted avg       0.69      0.72      0.68       531\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = make_baseline_clf()\n",
    "clf.set_params(vect__tokenizer=tokenize)\n",
    "\n",
    "clf.fit(X_oleh_train, y_oleh_train)\n",
    "validation_report(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nb__alpha': 0.3,\n",
       " 'nb__fit_prior': False,\n",
       " 'vect__ngram_range': (1, 1),\n",
       " 'vect__tokenizer': <function __main__.tokenize(model)>}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameter_grid = [{'vect__ngram_range': [(1, 1), (1, 2), (1, 3), (2, 2), (2, 3), (3, 3)],\n",
    "                   'vect__tokenizer': [tokenize, lemmatize],\n",
    "                   'nb__alpha': [1e-10, 0.001, 0.01, 0.05, 0.1, 0.3, 0.5, 1],\n",
    "                   'nb__fit_prior': [True, False],\n",
    "                  }]\n",
    "\n",
    "gs_clf = GridSearchCV(make_baseline_clf(), parameter_grid, scoring='f1_macro')\n",
    "gs_clf.fit(X_oleh_train, y_oleh_train)\n",
    "gs_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oleh:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       0.56      0.58      0.57       110\n",
      "        tell       0.79      0.77      0.78       222\n",
      "\n",
      "    accuracy                           0.71       332\n",
      "   macro avg       0.67      0.68      0.67       332\n",
      "weighted avg       0.71      0.71      0.71       332\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Scraped:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       0.81      0.33      0.46        40\n",
      "        tell       0.46      0.88      0.61        26\n",
      "\n",
      "    accuracy                           0.55        66\n",
      "   macro avg       0.64      0.60      0.53        66\n",
      "weighted avg       0.67      0.55      0.52        66\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Katia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       0.16      0.40      0.23        15\n",
      "        tell       0.91      0.73      0.81       118\n",
      "\n",
      "    accuracy                           0.69       133\n",
      "   macro avg       0.53      0.56      0.52       133\n",
      "weighted avg       0.82      0.69      0.74       133\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "All:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       0.49      0.50      0.50       165\n",
      "        tell       0.77      0.77      0.77       366\n",
      "\n",
      "    accuracy                           0.68       531\n",
      "   macro avg       0.63      0.63      0.63       531\n",
      "weighted avg       0.69      0.68      0.68       531\n",
      "\n"
     ]
    }
   ],
   "source": [
    "validation_report(gs_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Покращена версія"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def ds_func(f):\n",
    "    return lambda X: [f(x) for x in X]\n",
    "\n",
    "def combine_extractors(funcs):\n",
    "    def combined(x):\n",
    "        feats = {}\n",
    "        for e in funcs:\n",
    "            feats.update(e(x))\n",
    "        return feats\n",
    "    return combined\n",
    "\n",
    "def make_rfc_classifier(*feature_extractors):\n",
    "    classifier = Pipeline([('extractor', FunctionTransformer()),\n",
    "                           ('dict_vect', DictVectorizer()),\n",
    "                           ('rfc', RandomForestClassifier(random_state=42))])\n",
    "    params = {'extractor__func': ds_func(combine_extractors(feature_extractors))}\n",
    "    classifier.set_params(**params)\n",
    "    \n",
    "    return classifier\n",
    "\n",
    "def make_lrc_classifier(*feature_extractors):\n",
    "    classifier = Pipeline([('extractor', FunctionTransformer()),\n",
    "                           ('dict_vect', DictVectorizer()),\n",
    "                           ('lrc', LogisticRegression())])\n",
    "        \n",
    "    params = {'lrc__random_state': 42,\n",
    "              'lrc__solver': 'sag',\n",
    "              'lrc__multi_class': 'multinomial',\n",
    "              'lrc__max_iter': 5000,\n",
    "              'extractor__func': ds_func(combine_extractors(feature_extractors))}\n",
    "    classifier.set_params(**params)\n",
    "\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Витягую частотність POS i DEP тегів\n",
    "### Тут використовую Random Forest, бо логістична регресія видає всюди нулі. Певно ці значення не fit-яться лінійною моделлю 🤔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PRON_num': 0.16666666666666666,\n",
       " 'VERB_num': 0.16666666666666666,\n",
       " 'NOUN_num': 0.16666666666666666,\n",
       " 'ADV_num': 0.3333333333333333,\n",
       " 'PUNCT_num': 0.16666666666666666}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def extract_pos_freqs(doc):\n",
    "    pos_freqs = Counter([tok.pos_ for tok in doc])    \n",
    "    return {pos + '_num': freq / len(doc) for pos, freq in pos_freqs.items()}\n",
    "\n",
    "extract_pos_freqs(nlp('I like cats very much.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oleh:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       0.61      0.25      0.35       110\n",
      "        tell       0.71      0.92      0.80       222\n",
      "\n",
      "    accuracy                           0.70       332\n",
      "   macro avg       0.66      0.58      0.58       332\n",
      "weighted avg       0.68      0.70      0.65       332\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Scraped:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       1.00      0.17      0.30        40\n",
      "        tell       0.44      1.00      0.61        26\n",
      "\n",
      "    accuracy                           0.50        66\n",
      "   macro avg       0.72      0.59      0.45        66\n",
      "weighted avg       0.78      0.50      0.42        66\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Katia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       0.06      0.07      0.06        15\n",
      "        tell       0.88      0.87      0.88       118\n",
      "\n",
      "    accuracy                           0.78       133\n",
      "   macro avg       0.47      0.47      0.47       133\n",
      "weighted avg       0.79      0.78      0.79       133\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "All:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       0.52      0.21      0.30       165\n",
      "        tell       0.72      0.91      0.80       366\n",
      "\n",
      "    accuracy                           0.69       531\n",
      "   macro avg       0.62      0.56      0.55       531\n",
      "weighted avg       0.66      0.69      0.65       531\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = make_rfc_classifier(extract_pos_freqs)\n",
    "clf.fit(X_oleh_train, y_oleh_train)\n",
    "validation_report(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dep_freqs(doc):\n",
    "    dep_freqs = Counter([tok.dep_ for tok in doc])\n",
    "    return {dep + '_num': freq / len(doc) for dep, freq in dep_freqs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oleh:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       0.50      0.25      0.34       110\n",
      "        tell       0.70      0.87      0.78       222\n",
      "\n",
      "    accuracy                           0.67       332\n",
      "   macro avg       0.60      0.56      0.56       332\n",
      "weighted avg       0.64      0.67      0.63       332\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Scraped:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       1.00      0.17      0.30        40\n",
      "        tell       0.44      1.00      0.61        26\n",
      "\n",
      "    accuracy                           0.50        66\n",
      "   macro avg       0.72      0.59      0.45        66\n",
      "weighted avg       0.78      0.50      0.42        66\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Katia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       0.14      0.13      0.14        15\n",
      "        tell       0.89      0.90      0.89       118\n",
      "\n",
      "    accuracy                           0.81       133\n",
      "   macro avg       0.52      0.52      0.52       133\n",
      "weighted avg       0.81      0.81      0.81       133\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "All:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       0.48      0.22      0.31       165\n",
      "        tell       0.72      0.89      0.80       366\n",
      "\n",
      "    accuracy                           0.68       531\n",
      "   macro avg       0.60      0.56      0.55       531\n",
      "weighted avg       0.64      0.68      0.64       531\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = make_rfc_classifier(extract_dep_freqs)\n",
    "clf.fit(X_oleh_train, y_oleh_train)\n",
    "validation_report(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Від комбінування цих фіч якість особливо не покращується :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oleh:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       0.56      0.26      0.36       110\n",
      "        tell       0.71      0.90      0.79       222\n",
      "\n",
      "    accuracy                           0.69       332\n",
      "   macro avg       0.63      0.58      0.58       332\n",
      "weighted avg       0.66      0.69      0.65       332\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Scraped:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       1.00      0.15      0.26        40\n",
      "        tell       0.43      1.00      0.60        26\n",
      "\n",
      "    accuracy                           0.48        66\n",
      "   macro avg       0.72      0.57      0.43        66\n",
      "weighted avg       0.78      0.48      0.40        66\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Katia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       0.07      0.07      0.07        15\n",
      "        tell       0.88      0.88      0.88       118\n",
      "\n",
      "    accuracy                           0.79       133\n",
      "   macro avg       0.47      0.47      0.47       133\n",
      "weighted avg       0.79      0.79      0.79       133\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "All:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       0.49      0.22      0.30       165\n",
      "        tell       0.72      0.90      0.80       366\n",
      "\n",
      "    accuracy                           0.69       531\n",
      "   macro avg       0.61      0.56      0.55       531\n",
      "weighted avg       0.65      0.69      0.64       531\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = make_rfc_classifier(extract_pos_freqs, extract_dep_freqs)\n",
    "clf.fit(X_oleh_train, y_oleh_train)\n",
    "validation_report(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Збираю інформацію про головні підмет і присудок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('emotions-dict.txt', 'r') as f:\n",
    "    emotions = set([x.strip() for x in f.readlines()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('abstract.txt', 'r') as f:\n",
    "    abstracts = set([x.strip() for x in f.readlines()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "573"
      ]
     },
     "execution_count": 590,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(abstracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_main_token(doc):\n",
    "    return [tok for tok in doc if tok.dep_ == 'ROOT'][0]\n",
    "\n",
    "def extract_subj_verb(doc):\n",
    "    feats = {}\n",
    "    main = find_main_token(doc)\n",
    "    \n",
    "    if main.pos_ == 'VERB':\n",
    "        feats['main-word'] = main.text\n",
    "        feats['main-pos'] = main.pos_\n",
    "        feats['main-lemma'] = main.lemma_\n",
    "        \n",
    "        subj = None\n",
    "        for tok in doc:\n",
    "            if tok.head.dep_ == 'ROOT' and tok.dep_ == 'nsubj':\n",
    "                subj = tok\n",
    "                break\n",
    "        if subj:\n",
    "            feats['subj-word'] = subj.text\n",
    "            feats['subj-pos'] = subj.pos_\n",
    "            feats['subj-lemma'] = subj.lemma_\n",
    "            \n",
    "    return feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Якість на рівні з попередніми класифікаторами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oleh:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       0.63      0.35      0.45       110\n",
      "        tell       0.74      0.90      0.81       222\n",
      "\n",
      "    accuracy                           0.72       332\n",
      "   macro avg       0.68      0.62      0.63       332\n",
      "weighted avg       0.70      0.72      0.69       332\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Scraped:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       1.00      0.07      0.14        40\n",
      "        tell       0.41      1.00      0.58        26\n",
      "\n",
      "    accuracy                           0.44        66\n",
      "   macro avg       0.71      0.54      0.36        66\n",
      "weighted avg       0.77      0.44      0.31        66\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Katia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       0.11      0.13      0.12        15\n",
      "        tell       0.89      0.86      0.88       118\n",
      "\n",
      "    accuracy                           0.78       133\n",
      "   macro avg       0.50      0.50      0.50       133\n",
      "weighted avg       0.80      0.78      0.79       133\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "All:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       0.53      0.26      0.35       165\n",
      "        tell       0.73      0.90      0.80       366\n",
      "\n",
      "    accuracy                           0.70       531\n",
      "   macro avg       0.63      0.58      0.58       531\n",
      "weighted avg       0.67      0.70      0.66       531\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = make_lrc_classifier(extract_subj_verb)\n",
    "clf.fit(X_oleh_train, y_oleh_train)\n",
    "validation_report(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Контекст підмету і присудка. Якість в порівнянні з RF трішки покращилася"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mom, None, None, None], [cats, None, None, None])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ctx(x, size, check_important=True):\n",
    "    lefts = x.doc[:x.i]\n",
    "    rights = x.doc[x.i+1:]\n",
    "\n",
    "    left_ctx = [x for x in lefts if not check_important or is_important(x)][-size:]\n",
    "    if len(left_ctx) < size:\n",
    "        left_ctx = ([None] * (size - len(left_ctx))) + left_ctx\n",
    "    \n",
    "    right_ctx = [x for x in rights if not check_important or is_important(x)][:size]\n",
    "    if len(right_ctx) < size:\n",
    "        right_ctx = right_ctx + ([None] * (size - len(right_ctx)))\n",
    "\n",
    "    return list(reversed(left_ctx)), right_ctx\n",
    "\n",
    "ctx(nlp('My mom likes cats very much')[2], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "# def retrieve_unigrams(ngrams):\n",
    "#     return {k:v for k, v in ngrams.items() if len(k.split(' ')) == 1}\n",
    "\n",
    "# unigrams = retrieve_unigrams(ngrams)\n",
    "# discretizer = KBinsDiscretizer(encode='ordinal', strategy='uniform', n_bins=8)\n",
    "# discretizer.fit([[sum(val)] for val in unigrams.values()])\n",
    "\n",
    "# def unigram_freq_discr(word):\n",
    "#     return discretizer.transform([[sum(get_freqs([word]))]])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('nice.a.01'),\n",
       " Synset('decent.s.01'),\n",
       " Synset('nice.s.03'),\n",
       " Synset('dainty.s.04'),\n",
       " Synset('courteous.s.01')]"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('nice', 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('nice.a.01'),\n",
       " Synset('decent.s.01'),\n",
       " Synset('nice.s.03'),\n",
       " Synset('dainty.s.04'),\n",
       " Synset('courteous.s.01')]"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pos_synsets(lemma, pos):\n",
    "    if pos == 'NOUN':\n",
    "        return wn.synsets(lemma, 'n')\n",
    "    if pos == 'VERB':\n",
    "        return wn.synsets(lemma, 'v')\n",
    "    if pos == 'ADV':\n",
    "        return wn.synsets(lemma, 'r')\n",
    "    if pos == 'ADJ':\n",
    "        return wn.synsets(lemma, 'a')\n",
    "    return []\n",
    "\n",
    "pos_synsets('nice', 'ADJ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_subj_verb_ctx(doc):\n",
    "    feats = {}\n",
    "    main = find_main_token(doc)\n",
    "    \n",
    "    if main.pos_ == 'VERB':\n",
    "        left_ctx, right_ctx = ctx(main, 3)\n",
    "\n",
    "#         feats['main-4-word'] = left_ctx[3].text if left_ctx[3] else '<<<none>>>'\n",
    "#         feats['main-4-pos'] = left_ctx[3].pos_ if left_ctx[3] else '<<<none>>>'\n",
    "#         feats['main-4-lemma'] = left_ctx[3].lemma_ if left_ctx[3] else '<<<none>>>'\n",
    "        feats['main-3-word'] = left_ctx[2].lower_ if left_ctx[2] else '<<<none>>>'\n",
    "        feats['main-2-word'] = left_ctx[1].lower_ if left_ctx[1] else '<<<none>>>'\n",
    "        feats['main-1-word'] = left_ctx[0].lower_ if left_ctx[0] else '<<<none>>>'\n",
    "        feats['main+1-word'] = right_ctx[0].lower_ if right_ctx[0] else '<<<none>>>'\n",
    "        feats['main+2-word'] = right_ctx[1].lower_ if right_ctx[1] else '<<<none>>>'\n",
    "        feats['main+3-word'] = right_ctx[2].lower_ if right_ctx[2] else '<<<none>>>'\n",
    "        \n",
    "        \n",
    "        feats['main-3-pos'] = left_ctx[2].pos_ if left_ctx[2] else '<<<none>>>'\n",
    "        feats['main-2-pos'] = left_ctx[1].pos_ if left_ctx[1] else '<<<none>>>'\n",
    "        feats['main-1-pos'] = left_ctx[0].pos_ if left_ctx[0] else '<<<none>>>'\n",
    "        feats['main+1-pos'] = right_ctx[0].pos_ if right_ctx[0] else '<<<none>>>'\n",
    "        feats['main+2-pos'] = right_ctx[1].pos_ if right_ctx[1] else '<<<none>>>'\n",
    "        feats['main+3-pos'] = right_ctx[2].pos_ if right_ctx[2] else '<<<none>>>'\n",
    "        \n",
    "        feats['main-3-lemma'] = left_ctx[2].lemma_ if left_ctx[2] else '<<<none>>>'\n",
    "        feats['main-2-lemma'] = left_ctx[1].lemma_ if left_ctx[1] else '<<<none>>>'\n",
    "        feats['main-1-lemma'] = left_ctx[0].lemma_ if left_ctx[0] else '<<<none>>>'\n",
    "        feats['main+1-lemma'] = right_ctx[0].lemma_ if right_ctx[0] else '<<<none>>>'\n",
    "        feats['main+2-lemma'] = right_ctx[1].lemma_ if right_ctx[1] else '<<<none>>>'\n",
    "        feats['main+3-lemma'] = right_ctx[2].lemma_ if right_ctx[2] else '<<<none>>>'\n",
    "\n",
    "        feats['main-3-is-emotion'] = left_ctx[2].lower_ in emotions if left_ctx[2] else False\n",
    "        feats['main-2-is-emotion'] = left_ctx[1].lower_ in emotions if left_ctx[1] else False\n",
    "        feats['main-1-is-emotion'] = left_ctx[0].lower_ in emotions if left_ctx[0] else False\n",
    "        feats['main+1-is-emotion'] = right_ctx[0].lower_ in emotions if right_ctx[0] else False\n",
    "        feats['main+2-is-emotion'] = right_ctx[1].lower_ in emotions if right_ctx[1] else False\n",
    "        feats['main+3-is-emotion'] = right_ctx[2].lower_ in emotions if right_ctx[2] else False\n",
    "\n",
    "        feats['main-3-is-emotion'] = left_ctx[2].lower_ in emotions if left_ctx[2] else False\n",
    "        feats['main-2-is-emotion'] = left_ctx[1].lower_ in emotions if left_ctx[1] else False\n",
    "        feats['main-1-is-emotion'] = left_ctx[0].lower_ in emotions if left_ctx[0] else False\n",
    "        feats['main+1-is-emotion'] = right_ctx[0].lower_ in emotions if right_ctx[0] else False\n",
    "        feats['main+2-is-emotion'] = right_ctx[1].lower_ in emotions if right_ctx[1] else False\n",
    "        feats['main+3-is-emotion'] = right_ctx[2].lower_ in emotions if right_ctx[2] else False\n",
    "\n",
    "#         feats['main-3-n-synonyms'] = len(pos_synsets(left_ctx[2].lemma_, left_ctx[2].pos_)) if left_ctx[2] else 0\n",
    "#         feats['main-2-n-synonyms'] = len(pos_synsets(left_ctx[1].lemma_, left_ctx[1].pos_)) if left_ctx[1] else 0\n",
    "#         feats['main-1-n-synonyms'] = len(pos_synsets(left_ctx[0].lemma_, left_ctx[0].pos_)) if left_ctx[0] else 0\n",
    "#         feats['main+1-n-synonyms'] = len(pos_synsets(right_ctx[0].lemma_, right_ctx[0].pos_)) if right_ctx[0] else False\n",
    "#         feats['main+2-n-synonyms'] = len(pos_synsets(right_ctx[1].lemma_, right_ctx[1].pos_)) if right_ctx[1] else False\n",
    "#         feats['main+3-n-synonyms'] = len(pos_synsets(right_ctx[2].lemma_, right_ctx[2].pos_)) if right_ctx[2] else False\n",
    "\n",
    "        feats['main-3-abstract'] = left_ctx[2].lower_ in abstracts if left_ctx[2] else False\n",
    "        feats['main-2-abstract'] = left_ctx[1].lower_ in abstracts if left_ctx[1] else False\n",
    "        feats['main-1-abstract'] = left_ctx[0].lower_ in abstracts if left_ctx[0] else False\n",
    "        feats['main+1-abstract'] = right_ctx[0].lower_ in abstracts if right_ctx[0] else False\n",
    "        feats['main+2-abstract'] = right_ctx[1].lower_ in abstracts if right_ctx[1] else False\n",
    "        feats['main+3-abstract'] = right_ctx[2].lower_ in abstracts if right_ctx[2] else False\n",
    "\n",
    "\n",
    "        mrc_word = mrc.get(left_ctx[2].text.upper()) if left_ctx[2] else None\n",
    "        if mrc_word:\n",
    "            feats['main-3-kf_freq'] = mrc_word.kf_freq if mrc_word.kf_freq else 0\n",
    "            feats['main-3-kf_ncats'] = mrc_word.kf_ncats if mrc_word.kf_ncats else 0\n",
    "            feats['main-3-kf_nsamp'] = mrc_word.kf_nsamp if mrc_word.kf_nsamp else 0\n",
    "            feats['main-3-tl_freq'] = mrc_word.tl_freq if mrc_word.tl_freq else 0\n",
    "            feats['main-3-brown_freq'] = mrc_word.brown_freq if mrc_word.brown_freq else 0\n",
    "            feats['main-3-fam'] = mrc_word.fam if mrc_word.fam else 0\n",
    "            feats['main-3-conc'] = mrc_word.conc if mrc_word.conc else 0\n",
    "            feats['main-3-imag'] = mrc_word.imag if mrc_word.imag else 0\n",
    "            feats['main-3-meanc'] = mrc_word.meanc if mrc_word.meanc else 0\n",
    "            feats['main-3-meanp'] = mrc_word.meanp if mrc_word.meanp else 0\n",
    "\n",
    "        mrc_word = mrc.get(left_ctx[1].text.upper()) if left_ctx[1] else None\n",
    "        if mrc_word:\n",
    "            feats['main-2-kf_freq'] = mrc_word.kf_freq if mrc_word.kf_freq else 0\n",
    "            feats['main-2-kf_ncats'] = mrc_word.kf_ncats if mrc_word.kf_ncats else 0\n",
    "            feats['main-2-kf_nsamp'] = mrc_word.kf_nsamp if mrc_word.kf_nsamp else 0\n",
    "            feats['main-2-tl_freq'] = mrc_word.tl_freq if mrc_word.tl_freq else 0\n",
    "            feats['main-2-brown_freq'] = mrc_word.brown_freq if mrc_word.brown_freq else 0\n",
    "            feats['main-2-fam'] = mrc_word.fam if mrc_word.fam else 0\n",
    "            feats['main-2-conc'] = mrc_word.conc if mrc_word.conc else 0\n",
    "            feats['main-2-imag'] = mrc_word.imag if mrc_word.imag else 0\n",
    "            feats['main-2-meanc'] = mrc_word.meanc if mrc_word.meanc else 0\n",
    "            feats['main-2-meanp'] = mrc_word.meanp if mrc_word.meanp else 0\n",
    "\n",
    "        mrc_word = mrc.get(left_ctx[0].text.upper()) if left_ctx[0] else None\n",
    "        if mrc_word:\n",
    "            feats['main-1-kf_freq'] = mrc_word.kf_freq if mrc_word.kf_freq else 0\n",
    "            feats['main-1-kf_ncats'] = mrc_word.kf_ncats if mrc_word.kf_ncats else 0\n",
    "            feats['main-1-kf_nsamp'] = mrc_word.kf_nsamp if mrc_word.kf_nsamp else 0\n",
    "            feats['main-1-tl_freq'] = mrc_word.tl_freq if mrc_word.tl_freq else 0\n",
    "            feats['main-1-brown_freq'] = mrc_word.brown_freq if mrc_word.brown_freq else 0\n",
    "            feats['main-1-fam'] = mrc_word.fam if mrc_word.fam else 0\n",
    "            feats['main-1-conc'] = mrc_word.conc if mrc_word.conc else 0\n",
    "            feats['main-1-imag'] = mrc_word.imag if mrc_word.imag else 0\n",
    "            feats['main-1-meanc'] = mrc_word.meanc if mrc_word.meanc else 0\n",
    "            feats['main-1-meanp'] = mrc_word.meanp if mrc_word.meanp else 0\n",
    "\n",
    "        mrc_word = mrc.get(right_ctx[0].text.upper()) if right_ctx[0] else None\n",
    "        if mrc_word:\n",
    "            feats['main+1-kf_freq'] = mrc_word.kf_freq if mrc_word.kf_freq else 0\n",
    "            feats['main+1-kf_ncats'] = mrc_word.kf_ncats if mrc_word.kf_ncats else 0\n",
    "            feats['main+1-kf_nsamp'] = mrc_word.kf_nsamp if mrc_word.kf_nsamp else 0\n",
    "            feats['main+1-tl_freq'] = mrc_word.tl_freq if mrc_word.tl_freq else 0\n",
    "            feats['main+1-brown_freq'] = mrc_word.brown_freq if mrc_word.brown_freq else 0\n",
    "            feats['main+1-fam'] = mrc_word.fam if mrc_word.fam else 0\n",
    "            feats['main+1-conc'] = mrc_word.conc if mrc_word.conc else 0\n",
    "            feats['main+1-imag'] = mrc_word.imag if mrc_word.imag else 0\n",
    "            feats['main+1-meanc'] = mrc_word.meanc if mrc_word.meanc else 0\n",
    "            feats['main+1-meanp'] = mrc_word.meanp if mrc_word.meanp else 0\n",
    "\n",
    "        mrc_word = mrc.get(right_ctx[1].text.upper()) if right_ctx[1] else None\n",
    "        if mrc_word:\n",
    "            feats['main+2-kf_freq'] = mrc_word.kf_freq if mrc_word.kf_freq else 0\n",
    "            feats['main+2-kf_ncats'] = mrc_word.kf_ncats if mrc_word.kf_ncats else 0\n",
    "            feats['main+2-kf_nsamp'] = mrc_word.kf_nsamp if mrc_word.kf_nsamp else 0\n",
    "            feats['main+2-tl_freq'] = mrc_word.tl_freq if mrc_word.tl_freq else 0\n",
    "            feats['main+2-brown_freq'] = mrc_word.brown_freq if mrc_word.brown_freq else 0\n",
    "            feats['main+2-fam'] = mrc_word.fam if mrc_word.fam else 0\n",
    "            feats['main+2-conc'] = mrc_word.conc if mrc_word.conc else 0\n",
    "            feats['main+2-imag'] = mrc_word.imag if mrc_word.imag else 0\n",
    "            feats['main+2-meanc'] = mrc_word.meanc if mrc_word.meanc else 0\n",
    "            feats['main+2-meanp'] = mrc_word.meanp if mrc_word.meanp else 0\n",
    "\n",
    "        mrc_word = mrc.get(right_ctx[2].text.upper()) if right_ctx[2] else None\n",
    "        if mrc_word:\n",
    "            feats['main+3-kf_freq'] = mrc_word.kf_freq if mrc_word.kf_freq else 0\n",
    "            feats['main+3-kf_ncats'] = mrc_word.kf_ncats if mrc_word.kf_ncats else 0\n",
    "            feats['main+3-kf_nsamp'] = mrc_word.kf_nsamp if mrc_word.kf_nsamp else 0\n",
    "            feats['main+3-tl_freq'] = mrc_word.tl_freq if mrc_word.tl_freq else 0\n",
    "            feats['main+3-brown_freq'] = mrc_word.brown_freq if mrc_word.brown_freq else 0\n",
    "            feats['main+3-fam'] = mrc_word.fam if mrc_word.fam else 0\n",
    "            feats['main+3-conc'] = mrc_word.conc if mrc_word.conc else 0\n",
    "            feats['main+3-imag'] = mrc_word.imag if mrc_word.imag else 0\n",
    "            feats['main+3-meanc'] = mrc_word.meanc if mrc_word.meanc else 0\n",
    "            feats['main+3-meanp'] = mrc_word.meanp if mrc_word.meanp else 0\n",
    "\n",
    "\n",
    "\n",
    "#         feats['main-3-freq-dicr'] = unigram_freq_discr(left_ctx[2].text) if left_ctx[2] else 0\n",
    "#         feats['main-2-freq-dicr'] = unigram_freq_discr(left_ctx[1].text) if left_ctx[1] else 0\n",
    "#         feats['main-1-freq-dicr'] = unigram_freq_discr(left_ctx[0].text) if left_ctx[0] else 0\n",
    "#         feats['main+1-freq-dicr'] = unigram_freq_discr(right_ctx[0].text) if right_ctx[0] else 0\n",
    "#         feats['main+2-freq-dicr'] = unigram_freq_discr(right_ctx[1].text) if right_ctx[1] else 0\n",
    "#         feats['main+3-freq-dicr'] = unigram_freq_discr(right_ctx[2].text) if right_ctx[2] else 0\n",
    "\n",
    "#         feats['main+4-word'] = right_ctx[3].text if right_ctx[3] else '<<<none>>>'\n",
    "#         feats['main+4-pos'] = right_ctx[3].pos_ if right_ctx[3] else '<<<none>>>'\n",
    "#         feats['main+4-lemma'] = right_ctx[3].lemma_ if right_ctx[3] else '<<<none>>>'\n",
    "        \n",
    "        subj = None\n",
    "        for tok in doc:\n",
    "            if tok.head.dep_ == 'ROOT' and tok.dep_ == 'nsubj':\n",
    "                subj = tok\n",
    "                break\n",
    "        if subj:\n",
    "            left_ctx, right_ctx = ctx(subj, 3)\n",
    "#             feats['subj-4-word'] = left_ctx[3].text if left_ctx[3] else '<<<none>>>'\n",
    "#             feats['subj-4-pos'] = left_ctx[3].pos_ if left_ctx[3] else '<<<none>>>'\n",
    "#             feats['subj-4-lemma'] = left_ctx[3].lemma_ if left_ctx[3] else '<<<none>>>'\n",
    "            \n",
    "            feats['subj-3-word'] = left_ctx[2].lower_ if left_ctx[2] else '<<<none>>>'\n",
    "            feats['subj-2-word'] = left_ctx[1].lower_ if left_ctx[1] else '<<<none>>>'\n",
    "            feats['subj-1-word'] = left_ctx[0].lower_ if left_ctx[0] else '<<<none>>>'\n",
    "            feats['subj+1-word'] = right_ctx[0].lower_ if right_ctx[0] else '<<<none>>>'\n",
    "            feats['subj+2-word'] = right_ctx[1].lower_ if right_ctx[1] else '<<<none>>>'\n",
    "            feats['subj+3-word'] = right_ctx[2].lower_ if right_ctx[2] else '<<<none>>>'\n",
    "            \n",
    "            feats['subj-3-pos'] = left_ctx[2].pos_ if left_ctx[2] else '<<<none>>>'\n",
    "            feats['subj-2-pos'] = left_ctx[1].pos_ if left_ctx[1] else '<<<none>>>'\n",
    "            feats['subj-1-pos'] = left_ctx[0].pos_ if left_ctx[0] else '<<<none>>>'\n",
    "            feats['subj+1-pos'] = right_ctx[0].pos_ if right_ctx[0] else '<<<none>>>'\n",
    "            feats['subj+2-pos'] = right_ctx[1].pos_ if right_ctx[1] else '<<<none>>>'\n",
    "            feats['subj+3-pos'] = right_ctx[2].pos_ if right_ctx[2] else '<<<none>>>'\n",
    "            \n",
    "            feats['subj-3-lemma'] = left_ctx[2].lemma_ if left_ctx[2] else '<<<none>>>'\n",
    "            feats['subj-2-lemma'] = left_ctx[1].lemma_ if left_ctx[1] else '<<<none>>>'\n",
    "            feats['subj-1-lemma'] = left_ctx[0].lemma_ if left_ctx[0] else '<<<none>>>'\n",
    "            feats['subj+1-lemma'] = right_ctx[0].lemma_ if right_ctx[0] else '<<<none>>>'\n",
    "            feats['subj+2-lemma'] = right_ctx[1].lemma_ if right_ctx[1] else '<<<none>>>'\n",
    "            feats['subj+3-lemma'] = right_ctx[2].lemma_ if right_ctx[2] else '<<<none>>>'\n",
    "\n",
    "            feats['subj-3-is-emotion'] = left_ctx[2].lower_ in emotions if left_ctx[2] else False\n",
    "            feats['subj-2-is-emotion'] = left_ctx[1].lower_ in emotions if left_ctx[1] else False\n",
    "            feats['subj-1-is-emotion'] = left_ctx[0].lower_ in emotions if left_ctx[0] else False\n",
    "            feats['subj+1-is-emotion'] = right_ctx[0].lower_ in emotions if right_ctx[0] else False\n",
    "            feats['subj+2-is-emotion'] = right_ctx[1].lower_ in emotions if right_ctx[1] else False\n",
    "            feats['subj+3-is-emotion'] = right_ctx[2].lower_ in emotions if right_ctx[2] else False\n",
    "\n",
    "            feats['subj-3-abstract'] = left_ctx[2].lower_ in abstracts if left_ctx[2] else False\n",
    "            feats['subj-2-abstract'] = left_ctx[1].lower_ in abstracts if left_ctx[1] else False\n",
    "            feats['subj-1-abstract'] = left_ctx[0].lower_ in abstracts if left_ctx[0] else False\n",
    "            feats['subj+1-abstract'] = right_ctx[0].lower_ in abstracts if right_ctx[0] else False\n",
    "            feats['subj+2-abstract'] = right_ctx[1].lower_ in abstracts if right_ctx[1] else False\n",
    "            feats['subj+3-abstract'] = right_ctx[2].lower_ in abstracts if right_ctx[2] else False\n",
    "\n",
    "            mrc_word = mrc.get(left_ctx[2].text.upper()) if left_ctx[2] else None\n",
    "            if mrc_word:\n",
    "                feats['subj-3-kf_freq'] = mrc_word.kf_freq if mrc_word.kf_freq else 0\n",
    "                feats['subj-3-kf_ncats'] = mrc_word.kf_ncats if mrc_word.kf_ncats else 0\n",
    "                feats['subj-3-kf_nsamp'] = mrc_word.kf_nsamp if mrc_word.kf_nsamp else 0\n",
    "                feats['subj-3-tl_freq'] = mrc_word.tl_freq if mrc_word.tl_freq else 0\n",
    "                feats['subj-3-brown_freq'] = mrc_word.brown_freq if mrc_word.brown_freq else 0\n",
    "                feats['subj-3-fam'] = mrc_word.fam if mrc_word.fam else 0\n",
    "                feats['subj-3-conc'] = mrc_word.conc if mrc_word.conc else 0\n",
    "                feats['subj-3-imag'] = mrc_word.imag if mrc_word.imag else 0\n",
    "                feats['subj-3-meanc'] = mrc_word.meanc if mrc_word.meanc else 0\n",
    "                feats['subj-3-meanp'] = mrc_word.meanp if mrc_word.meanp else 0\n",
    "\n",
    "            mrc_word = mrc.get(left_ctx[1].text.upper()) if left_ctx[1] else None\n",
    "            if mrc_word:\n",
    "                feats['subj-2-kf_freq'] = mrc_word.kf_freq if mrc_word.kf_freq else 0\n",
    "                feats['subj-2-kf_ncats'] = mrc_word.kf_ncats if mrc_word.kf_ncats else 0\n",
    "                feats['subj-2-kf_nsamp'] = mrc_word.kf_nsamp if mrc_word.kf_nsamp else 0\n",
    "                feats['subj-2-tl_freq'] = mrc_word.tl_freq if mrc_word.tl_freq else 0\n",
    "                feats['subj-2-brown_freq'] = mrc_word.brown_freq if mrc_word.brown_freq else 0\n",
    "                feats['subj-2-fam'] = mrc_word.fam if mrc_word.fam else 0\n",
    "                feats['subj-2-conc'] = mrc_word.conc if mrc_word.conc else 0\n",
    "                feats['subj-2-imag'] = mrc_word.imag if mrc_word.imag else 0\n",
    "                feats['subj-2-meanc'] = mrc_word.meanc if mrc_word.meanc else 0\n",
    "                feats['subj-2-meanp'] = mrc_word.meanp if mrc_word.meanp else 0\n",
    "\n",
    "            mrc_word = mrc.get(left_ctx[0].text.upper()) if left_ctx[0] else None\n",
    "            if mrc_word:\n",
    "                feats['subj-1-kf_freq'] = mrc_word.kf_freq if mrc_word.kf_freq else 0\n",
    "                feats['subj-1-kf_ncats'] = mrc_word.kf_ncats if mrc_word.kf_ncats else 0\n",
    "                feats['subj-1-kf_nsamp'] = mrc_word.kf_nsamp if mrc_word.kf_nsamp else 0\n",
    "                feats['subj-1-tl_freq'] = mrc_word.tl_freq if mrc_word.tl_freq else 0\n",
    "                feats['subj-1-brown_freq'] = mrc_word.brown_freq if mrc_word.brown_freq else 0\n",
    "                feats['subj-1-fam'] = mrc_word.fam if mrc_word.fam else 0\n",
    "                feats['subj-1-conc'] = mrc_word.conc if mrc_word.conc else 0\n",
    "                feats['subj-1-imag'] = mrc_word.imag if mrc_word.imag else 0\n",
    "                feats['subj-1-meanc'] = mrc_word.meanc if mrc_word.meanc else 0\n",
    "                feats['subj-1-meanp'] = mrc_word.meanp if mrc_word.meanp else 0\n",
    "\n",
    "            mrc_word = mrc.get(right_ctx[0].text.upper()) if right_ctx[0] else None\n",
    "            if mrc_word:\n",
    "                feats['subj+1-kf_freq'] = mrc_word.kf_freq if mrc_word.kf_freq else 0\n",
    "                feats['subj+1-kf_ncats'] = mrc_word.kf_ncats if mrc_word.kf_ncats else 0\n",
    "                feats['subj+1-kf_nsamp'] = mrc_word.kf_nsamp if mrc_word.kf_nsamp else 0\n",
    "                feats['subj+1-tl_freq'] = mrc_word.tl_freq if mrc_word.tl_freq else 0\n",
    "                feats['subj+1-brown_freq'] = mrc_word.brown_freq if mrc_word.brown_freq else 0\n",
    "                feats['subj+1-fam'] = mrc_word.fam if mrc_word.fam else 0\n",
    "                feats['subj+1-conc'] = mrc_word.conc if mrc_word.conc else 0\n",
    "                feats['subj+1-imag'] = mrc_word.imag if mrc_word.imag else 0\n",
    "                feats['subj+1-meanc'] = mrc_word.meanc if mrc_word.meanc else 0\n",
    "                feats['subj+1-meanp'] = mrc_word.meanp if mrc_word.meanp else 0\n",
    "\n",
    "            mrc_word = mrc.get(right_ctx[1].text.upper()) if right_ctx[1] else None\n",
    "            if mrc_word:\n",
    "                feats['subj+2-kf_freq'] = mrc_word.kf_freq if mrc_word.kf_freq else 0\n",
    "                feats['subj+2-kf_ncats'] = mrc_word.kf_ncats if mrc_word.kf_ncats else 0\n",
    "                feats['subj+2-kf_nsamp'] = mrc_word.kf_nsamp if mrc_word.kf_nsamp else 0\n",
    "                feats['subj+2-tl_freq'] = mrc_word.tl_freq if mrc_word.tl_freq else 0\n",
    "                feats['subj+2-brown_freq'] = mrc_word.brown_freq if mrc_word.brown_freq else 0\n",
    "                feats['subj+2-fam'] = mrc_word.fam if mrc_word.fam else 0\n",
    "                feats['subj+2-conc'] = mrc_word.conc if mrc_word.conc else 0\n",
    "                feats['subj+2-imag'] = mrc_word.imag if mrc_word.imag else 0\n",
    "                feats['subj+2-meanc'] = mrc_word.meanc if mrc_word.meanc else 0\n",
    "                feats['subj+2-meanp'] = mrc_word.meanp if mrc_word.meanp else 0\n",
    "\n",
    "            mrc_word = mrc.get(right_ctx[2].text.upper()) if right_ctx[2] else None\n",
    "            if mrc_word:\n",
    "                feats['subj+3-kf_freq'] = mrc_word.kf_freq if mrc_word.kf_freq else 0\n",
    "                feats['subj+3-kf_ncats'] = mrc_word.kf_ncats if mrc_word.kf_ncats else 0\n",
    "                feats['subj+3-kf_nsamp'] = mrc_word.kf_nsamp if mrc_word.kf_nsamp else 0\n",
    "                feats['subj+3-tl_freq'] = mrc_word.tl_freq if mrc_word.tl_freq else 0\n",
    "                feats['subj+3-brown_freq'] = mrc_word.brown_freq if mrc_word.brown_freq else 0\n",
    "                feats['subj+3-fam'] = mrc_word.fam if mrc_word.fam else 0\n",
    "                feats['subj+3-conc'] = mrc_word.conc if mrc_word.conc else 0\n",
    "                feats['subj+3-imag'] = mrc_word.imag if mrc_word.imag else 0\n",
    "                feats['subj+3-meanc'] = mrc_word.meanc if mrc_word.meanc else 0\n",
    "                feats['subj+3-meanp'] = mrc_word.meanp if mrc_word.meanp else 0\n",
    "\n",
    "\n",
    "            \n",
    "#             feats['subj-3-n-synonyms'] = len(pos_synsets(left_ctx[2].lemma_, left_ctx[2].pos_)) if left_ctx[2] else 0\n",
    "#             feats['subj-2-n-synonyms'] = len(pos_synsets(left_ctx[1].lemma_, left_ctx[1].pos_)) if left_ctx[1] else 0\n",
    "#             feats['subj-1-n-synonyms'] = len(pos_synsets(left_ctx[0].lemma_, left_ctx[0].pos_)) if left_ctx[0] else 0\n",
    "#             feats['subj+1-n-synonyms'] = len(pos_synsets(right_ctx[0].lemma_, right_ctx[0].pos_)) if right_ctx[0] else False\n",
    "#             feats['subj+2-n-synonyms'] = len(pos_synsets(right_ctx[1].lemma_, right_ctx[1].pos_)) if right_ctx[1] else False\n",
    "#             feats['subj+3-n-synonyms'] = len(pos_synsets(right_ctx[2].lemma_, right_ctx[2].pos_)) if right_ctx[2] else False\n",
    "\n",
    "#             feats['subj-3-freq-dicr'] = unigram_freq_discr(left_ctx[2].text) if left_ctx[2] else 0\n",
    "#             feats['subj-2-freq-dicr'] = unigram_freq_discr(left_ctx[1].text) if left_ctx[1] else 0\n",
    "#             feats['subj+1-freq-dicr'] = unigram_freq_discr(right_ctx[0].text) if right_ctx[0] else 0\n",
    "#             feats['subj+2-freq-dicr'] = unigram_freq_discr(right_ctx[1].text) if right_ctx[1] else 0\n",
    "#             feats['subj+3-freq-dicr'] = unigram_freq_discr(right_ctx[2].text) if right_ctx[2] else 0\n",
    "\n",
    "#             feats['subj+4-word'] = right_ctx[3].text if right_ctx[3] else '<<<none>>>'\n",
    "#             feats['subj+4-pos'] = right_ctx[3].pos_ if right_ctx[3] else '<<<none>>>'\n",
    "#             feats['subj+4-lemma'] = right_ctx[3].lemma_ if right_ctx[3] else '<<<none>>>'\n",
    "\n",
    "\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FOO'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'foo'.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oleh:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       0.55      0.35      0.42       110\n",
      "        tell       0.73      0.86      0.79       222\n",
      "\n",
      "    accuracy                           0.69       332\n",
      "   macro avg       0.64      0.60      0.61       332\n",
      "weighted avg       0.67      0.69      0.67       332\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Scraped:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       1.00      0.12      0.22        40\n",
      "        tell       0.43      1.00      0.60        26\n",
      "\n",
      "    accuracy                           0.47        66\n",
      "   macro avg       0.71      0.56      0.41        66\n",
      "weighted avg       0.77      0.47      0.37        66\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Katia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       0.20      0.20      0.20        15\n",
      "        tell       0.90      0.90      0.90       118\n",
      "\n",
      "    accuracy                           0.82       133\n",
      "   macro avg       0.55      0.55      0.55       133\n",
      "weighted avg       0.82      0.82      0.82       133\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "All:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       0.52      0.28      0.36       165\n",
      "        tell       0.73      0.88      0.80       366\n",
      "\n",
      "    accuracy                           0.69       531\n",
      "   macro avg       0.62      0.58      0.58       531\n",
      "weighted avg       0.66      0.69      0.66       531\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = make_lrc_classifier(extract_subj_verb, extract_subj_verb_ctx)\n",
    "clf.fit(X_oleh_train, y_oleh_train)\n",
    "validation_report(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'main-nsubj-word': 'I',\n",
       " 'main-nsubj-pos': 'PRON',\n",
       " 'main-nsubj-lemma': '-PRON-',\n",
       " 'main-ROOT-word': 'like',\n",
       " 'main-ROOT-pos': 'VERB',\n",
       " 'main-ROOT-lemma': 'like',\n",
       " 'main-dobj-word': 'cats',\n",
       " 'main-dobj-pos': 'NOUN',\n",
       " 'main-dobj-lemma': 'cat',\n",
       " 'main-advmod-word': 'much',\n",
       " 'main-advmod-pos': 'ADV',\n",
       " 'main-advmod-lemma': 'much'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_subj_verb_dependants(doc):\n",
    "    feats = {}\n",
    "    main = find_main_token(doc)\n",
    "    \n",
    "    if main.pos_ == 'VERB':\n",
    "        for tok in doc:\n",
    "            if tok.head.i == main.i:                \n",
    "                feats[f'main-{tok.dep_}-word'] = tok.text\n",
    "                feats[f'main-{tok.dep_}-pos'] = tok.pos_\n",
    "                feats[f'main-{tok.dep_}-lemma'] = tok.lemma_\n",
    "        \n",
    "        subj = None\n",
    "        for tok in doc:\n",
    "            if tok.head.dep_ == 'ROOT' and tok.dep_ == 'nsubj':\n",
    "                subj = tok\n",
    "                break\n",
    "        if subj:\n",
    "            for tok in doc:\n",
    "                if tok.head.i == subj.i:                \n",
    "                    feats[f'subj-{tok.dep_}-word'] = tok.text\n",
    "                    feats[f'subj-{tok.dep_}-pos'] = tok.pos_\n",
    "                    feats[f'subj-{tok.dep_}-lemma'] = tok.lemma_\n",
    "            \n",
    "    return feats\n",
    "\n",
    "extract_subj_verb_dependants(nlp('I like cats very much'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oleh:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       0.58      0.38      0.46       110\n",
      "        tell       0.74      0.86      0.79       222\n",
      "\n",
      "    accuracy                           0.70       332\n",
      "   macro avg       0.66      0.62      0.63       332\n",
      "weighted avg       0.68      0.70      0.68       332\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Scraped:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       1.00      0.12      0.22        40\n",
      "        tell       0.43      1.00      0.60        26\n",
      "\n",
      "    accuracy                           0.47        66\n",
      "   macro avg       0.71      0.56      0.41        66\n",
      "weighted avg       0.77      0.47      0.37        66\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Katia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       0.24      0.27      0.25        15\n",
      "        tell       0.91      0.89      0.90       118\n",
      "\n",
      "    accuracy                           0.82       133\n",
      "   macro avg       0.57      0.58      0.57       133\n",
      "weighted avg       0.83      0.82      0.82       133\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "All:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       0.54      0.31      0.39       165\n",
      "        tell       0.74      0.88      0.80       366\n",
      "\n",
      "    accuracy                           0.70       531\n",
      "   macro avg       0.64      0.59      0.60       531\n",
      "weighted avg       0.68      0.70      0.68       531\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = make_lrc_classifier(extract_subj_verb, extract_subj_verb_ctx, extract_subj_verb_dependants)\n",
    "clf.fit(X_oleh_train, y_oleh_train)\n",
    "validation_report(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'has-emotion': False}"
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_emotions(doc):\n",
    "    feats = {}\n",
    "    \n",
    "    feats['has-emotion'] = len([x for x in doc if x.lower_ in emotions]) > 0\n",
    "    \n",
    "    return feats\n",
    "\n",
    "extract_emotions(nlp('I am dead'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oleh:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       0.56      0.31      0.40        97\n",
      "        tell       0.73      0.88      0.80       206\n",
      "\n",
      "    accuracy                           0.70       303\n",
      "   macro avg       0.64      0.60      0.60       303\n",
      "weighted avg       0.67      0.70      0.67       303\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Scraped:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       1.00      0.12      0.22        40\n",
      "        tell       0.43      1.00      0.60        26\n",
      "\n",
      "    accuracy                           0.47        66\n",
      "   macro avg       0.71      0.56      0.41        66\n",
      "weighted avg       0.77      0.47      0.37        66\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Katia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       0.33      0.27      0.30        15\n",
      "        tell       0.91      0.93      0.92       118\n",
      "\n",
      "    accuracy                           0.86       133\n",
      "   macro avg       0.62      0.60      0.61       133\n",
      "weighted avg       0.84      0.86      0.85       133\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "All:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       0.55      0.26      0.35       152\n",
      "        tell       0.74      0.91      0.81       350\n",
      "\n",
      "    accuracy                           0.71       502\n",
      "   macro avg       0.64      0.58      0.58       502\n",
      "weighted avg       0.68      0.71      0.67       502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = make_lrc_classifier(extract_subj_verb, extract_subj_verb_ctx, extract_subj_verb_dependants)\n",
    "clf.fit(X_oleh_train, y_oleh_train)\n",
    "validation_report(EmotionsClf(clf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Використовую в якості фіч вектор речення і вектори головних підмета і присудка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vector_to_feats(prefix, vector):\n",
    "    feats = {}\n",
    "    \n",
    "    for i, x in enumerate(vector):\n",
    "        feats[prefix + str(i)] = x\n",
    "    \n",
    "    return feats\n",
    "\n",
    "def avg_vector(vectors):\n",
    "    vect = np.zeros(300)\n",
    "    \n",
    "    for v in vectors:\n",
    "        vect += v\n",
    "    return vect / len(vectors) if len(vectors) > 0 else vect\n",
    "\n",
    "def is_important(x):\n",
    "    return not x.is_stop and not x.pos_ == 'PROPN' and x.ent_iob_ == 'O'\n",
    "\n",
    "def extract_vector(doc):        \n",
    "    return vector_to_feats('sent_vect', avg_vector([x.vector for x in doc if is_important(x)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oleh:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       0.76      0.51      0.61       110\n",
      "        tell       0.79      0.92      0.85       222\n",
      "\n",
      "    accuracy                           0.78       332\n",
      "   macro avg       0.77      0.71      0.73       332\n",
      "weighted avg       0.78      0.78      0.77       332\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Scraped:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       0.86      0.15      0.26        40\n",
      "        tell       0.42      0.96      0.59        26\n",
      "\n",
      "    accuracy                           0.47        66\n",
      "   macro avg       0.64      0.56      0.42        66\n",
      "weighted avg       0.69      0.47      0.39        66\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Katia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       0.28      0.33      0.30        15\n",
      "        tell       0.91      0.89      0.90       118\n",
      "\n",
      "    accuracy                           0.83       133\n",
      "   macro avg       0.60      0.61      0.60       133\n",
      "weighted avg       0.84      0.83      0.83       133\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "All:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       0.68      0.41      0.51       165\n",
      "        tell       0.77      0.91      0.84       366\n",
      "\n",
      "    accuracy                           0.76       531\n",
      "   macro avg       0.72      0.66      0.67       531\n",
      "weighted avg       0.74      0.76      0.73       531\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = make_lrc_classifier(extract_vector)\n",
    "clf.fit(X_oleh_train, y_oleh_train)\n",
    "validation_report(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_subj_verb_vector(doc):\n",
    "    feats = {}\n",
    "    main = find_main_token(doc)\n",
    "    \n",
    "    if main.pos_ == 'VERB':\n",
    "        feats.update(vector_to_feats('main_vect', main.vector))\n",
    "        subj = None\n",
    "        for tok in doc:\n",
    "            if tok.head.dep_ == 'ROOT' and tok.dep_ == 'nsubj':\n",
    "                subj = tok\n",
    "                break\n",
    "        if subj:\n",
    "            feats.update(vector_to_feats('main_subj_vect', subj.vector))\n",
    "\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_subj_verb_ctx_vector(doc):\n",
    "    feats = {}\n",
    "    main = find_main_token(doc)\n",
    "    vects = []\n",
    "    \n",
    "    if main.pos_ == 'VERB':\n",
    "        left_ctx, right_ctx = ctx(main, 3, check_important=True)\n",
    "        \n",
    "        for x in left_ctx + right_ctx:\n",
    "            if x:\n",
    "                vects.append(x.vector)\n",
    "            \n",
    "        \n",
    "        subj = None\n",
    "        for tok in doc:\n",
    "            if tok.head.dep_ == 'ROOT' and tok.dep_ == 'nsubj':\n",
    "                subj = tok\n",
    "                break\n",
    "        if subj:\n",
    "            left_ctx, right_ctx = ctx(subj, 3, check_important=True)\n",
    "        \n",
    "            for x in left_ctx + right_ctx:\n",
    "                if x:\n",
    "                    vects.append(x.vector)\n",
    "            \n",
    "    return vector_to_feats('subj-verb-ctx', avg_vector(vects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oleh:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       0.66      0.55      0.60       110\n",
      "        tell       0.80      0.86      0.83       222\n",
      "\n",
      "    accuracy                           0.76       332\n",
      "   macro avg       0.73      0.71      0.72       332\n",
      "weighted avg       0.75      0.76      0.75       332\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Scraped:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       0.75      0.15      0.25        40\n",
      "        tell       0.41      0.92      0.57        26\n",
      "\n",
      "    accuracy                           0.45        66\n",
      "   macro avg       0.58      0.54      0.41        66\n",
      "weighted avg       0.62      0.45      0.38        66\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Katia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       0.11      0.27      0.16        15\n",
      "        tell       0.89      0.73      0.80       118\n",
      "\n",
      "    accuracy                           0.68       133\n",
      "   macro avg       0.50      0.50      0.48       133\n",
      "weighted avg       0.80      0.68      0.73       133\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "All:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       0.52      0.43      0.47       165\n",
      "        tell       0.76      0.82      0.79       366\n",
      "\n",
      "    accuracy                           0.70       531\n",
      "   macro avg       0.64      0.63      0.63       531\n",
      "weighted avg       0.69      0.70      0.69       531\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = make_lrc_classifier(extract_vector, extract_subj_verb_vector)\n",
    "clf.fit(X_oleh_train, y_oleh_train)\n",
    "validation_report(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Таке рішення трішки перевершує бейзлайн по якості.\n",
    "### Скомбінувавши вектори з попередніми фічами, якість ще трохи поліпшується."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionsClf():\n",
    "    def __init__(self, clf):\n",
    "        self.clf = clf\n",
    "    def predict(self, X):\n",
    "        labels = self.clf.predict(X)\n",
    "        new_labels = []\n",
    "        for doc, label in zip(X, labels):\n",
    "            if len([tok for tok in doc if tok.lower_ in emotions]) > 0:\n",
    "                new_labels.append('tell')\n",
    "            else:\n",
    "                new_labels.append(label)\n",
    "        return new_labels\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oleh:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       0.76      0.55      0.63       110\n",
      "        tell       0.80      0.91      0.85       222\n",
      "\n",
      "    accuracy                           0.79       332\n",
      "   macro avg       0.78      0.73      0.74       332\n",
      "weighted avg       0.79      0.79      0.78       332\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Scraped:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       0.83      0.12      0.22        40\n",
      "        tell       0.42      0.96      0.58        26\n",
      "\n",
      "    accuracy                           0.45        66\n",
      "   macro avg       0.62      0.54      0.40        66\n",
      "weighted avg       0.67      0.45      0.36        66\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Katia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       0.21      0.40      0.28        15\n",
      "        tell       0.91      0.81      0.86       118\n",
      "\n",
      "    accuracy                           0.77       133\n",
      "   macro avg       0.56      0.61      0.57       133\n",
      "weighted avg       0.84      0.77      0.80       133\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "All:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       0.63      0.43      0.51       165\n",
      "        tell       0.78      0.89      0.83       366\n",
      "\n",
      "    accuracy                           0.74       531\n",
      "   macro avg       0.70      0.66      0.67       531\n",
      "weighted avg       0.73      0.74      0.73       531\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = make_lrc_classifier(extract_vector, extract_subj_verb)\n",
    "clf.fit(X_oleh_train, y_oleh_train)\n",
    "validation_report(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.73234774, 0.26765226]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba([nlp('i am sad')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "\n",
    "corenlp = StanfordCoreNLP('/Users/oleh.palianytsia/Downloads/stanford-corenlp-full-2018-02-27')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(ADVP']"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "re.findall('\\\\(ADVP', corenlp.parse('I like cats very much'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/oleh.palianytsia/devel/show-dont-tell/raw_data/stories-sents.txt', 'r') as f:\n",
    "    stories_lines = [s.strip() for s in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "part = stories_lines[400000:500000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "part = list(nlp.pipe(part))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = clf.predict(part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/oleh.palianytsia/devel/show-dont-tell/to-annotate-2.csv', 'w') as f:\n",
    "    for doc, label in zip(part, labels):\n",
    "        if label == 'show' and len(doc.text) > 140:\n",
    "            f.write(doc.text)\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"'"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp('I was \"amazed\"')[2].lemma_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_cache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pp-num': 0.0, 'adjp-num': 0.0, 'advp-num': 0.2}"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_phrases_num(doc):\n",
    "    global parse_cache\n",
    "    if doc.text in parse_cache:\n",
    "        parse = parse_cache[doc.text]\n",
    "    else:\n",
    "        parse = corenlp.parse(doc.text)\n",
    "        parse_cache[doc.text] = parse\n",
    "\n",
    "    feats = {}\n",
    "    \n",
    "    feats['pp-num'] = len(re.findall('\\\\(PP', parse)) / len(doc)\n",
    "    feats['adjp-num'] = len(re.findall('\\\\(ADJP', parse)) / len(doc)\n",
    "    feats['advp-num'] = len(re.findall('\\\\(ADVP', parse)) / len(doc)\n",
    "\n",
    "    return feats\n",
    "\n",
    "extract_phrases_num(nlp('I like cats very much'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oleh:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       0.21      0.16      0.19        61\n",
      "        tell       0.78      0.83      0.80       215\n",
      "\n",
      "    accuracy                           0.68       276\n",
      "   macro avg       0.50      0.50      0.49       276\n",
      "weighted avg       0.65      0.68      0.67       276\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Scraped:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       0.73      0.20      0.31        40\n",
      "        tell       0.42      0.88      0.57        26\n",
      "\n",
      "    accuracy                           0.47        66\n",
      "   macro avg       0.57      0.54      0.44        66\n",
      "weighted avg       0.61      0.47      0.41        66\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Katia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       0.06      0.13      0.09        15\n",
      "        tell       0.87      0.75      0.80       118\n",
      "\n",
      "    accuracy                           0.68       133\n",
      "   macro avg       0.47      0.44      0.44       133\n",
      "weighted avg       0.78      0.68      0.72       133\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "All:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       0.22      0.17      0.19       116\n",
      "        tell       0.75      0.81      0.78       359\n",
      "\n",
      "    accuracy                           0.65       475\n",
      "   macro avg       0.49      0.49      0.49       475\n",
      "weighted avg       0.62      0.65      0.63       475\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = make_rfc_classifier(extract_phrases_num)\n",
    "clf.fit(X_oleh_train, y_oleh_train)\n",
    "validation_report(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Збираю н-грами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phrasefinder import phrasefinder as pf\n",
    "\n",
    "def fetch_ngram(text):\n",
    "#     print('fetching...')\n",
    "    try:\n",
    "        query = pf.escape_query_term(text)\n",
    "        result = pf.search(pf.Corpus.AMERICAN_ENGLISH, query)\n",
    "        if result.error:\n",
    "            print('WARN: request failed: {}'.format(result.error['message']))\n",
    "            return None\n",
    "\n",
    "        return [phrase.match_count for phrase in result.phrases] + [0]\n",
    "    except Exception as error:\n",
    "        print('Fatal error: {}'.format(error))\n",
    "        return None\n",
    "\n",
    "def process_ngram(ngram, res_dict):\n",
    "    def fetch_and_save(text):\n",
    "        if not text in res_dict:\n",
    "            freq = fetch_ngram(text)\n",
    "            if freq is not None:\n",
    "                res_dict[text] = freq\n",
    "    \n",
    "    formatted = ' '.join([x.lower() for x in ngram])\n",
    "    fetch_and_save(formatted)            \n",
    "    return res_dict\n",
    "\n",
    "def collect_ngrams(sents, n, res_dict):\n",
    "    print('starting...')\n",
    "    \n",
    "    for sent in sents:\n",
    "        ngrams = gen_ngrams(sent, n)\n",
    "        if ngrams:\n",
    "            for ngram in ngrams:\n",
    "                process_ngram(ngram, res_dict)\n",
    "    \n",
    "    print('done!')\n",
    "\n",
    "    return res_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_ngrams(toks, n):\n",
    "    if len(toks) >= n:\n",
    "        return [toks[i:i+n] for i in range(len(toks) - n + 1)]\n",
    "\n",
    "def get_freqs(toks):\n",
    "    return ngrams[' '.join([x.lower() for x in toks])]\n",
    "\n",
    "def get_or_fetch_freqs(toks):\n",
    "    process_ngram(toks, ngrams)\n",
    "    return get_freqs(toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=48)]: Using backend LokyBackend with 48 concurrent workers.\n",
      "[Parallel(n_jobs=48)]: Done   2 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=48)]: Done  17 tasks      | elapsed:   26.3s\n",
      "[Parallel(n_jobs=48)]: Done  32 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=48)]: Done  49 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=48)]: Done  66 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=48)]: Done  85 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=48)]: Done 104 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=48)]: Done 125 tasks      | elapsed:  3.1min\n",
      "/opt/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=48)]: Done 146 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=48)]: Done 169 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=48)]: Done 192 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=48)]: Done 217 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=48)]: Done 242 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=48)]: Done 269 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=48)]: Done 296 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=48)]: Done 325 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=48)]: Done 354 tasks      | elapsed:  7.7min\n",
      "[Parallel(n_jobs=48)]: Done 385 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=48)]: Done 416 tasks      | elapsed:  9.1min\n",
      "[Parallel(n_jobs=48)]: Done 449 tasks      | elapsed:  9.8min\n",
      "[Parallel(n_jobs=48)]: Done 482 tasks      | elapsed: 10.8min\n",
      "[Parallel(n_jobs=48)]: Done 517 tasks      | elapsed: 12.2min\n",
      "[Parallel(n_jobs=48)]: Done 552 tasks      | elapsed: 12.9min\n",
      "[Parallel(n_jobs=48)]: Done 589 tasks      | elapsed: 14.3min\n",
      "[Parallel(n_jobs=48)]: Done 626 tasks      | elapsed: 16.9min\n",
      "[Parallel(n_jobs=48)]: Done 665 tasks      | elapsed: 17.9min\n",
      "[Parallel(n_jobs=48)]: Done 704 tasks      | elapsed: 20.8min\n",
      "[Parallel(n_jobs=48)]: Done 786 out of 800 | elapsed: 24.6min remaining:   26.3s\n",
      "[Parallel(n_jobs=48)]: Done 800 out of 800 | elapsed: 24.9min finished\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import json\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "all_sents = pd.concat([oleh_dataset['sentence'].apply(tokenize), \n",
    "                       scraped_dataset['sentence'].apply(tokenize),\n",
    "                       katia_dataset['sentence'].apply(tokenize)])\n",
    "\n",
    "with open('ngrams.json', 'r') as f:\n",
    "    ngrams = json.load(f)\n",
    "\n",
    "def parallel_collect(sents, ngrams_map):\n",
    "    n_batches = 200\n",
    "    batch_size = math.ceil(len(all_sents) / n_batches)\n",
    "    gen = (delayed(collect_ngrams)(all_sents[i*batch_size:(i+1)*batch_size], n, ngrams)\n",
    "        for i in range(n_batches) for n in range(1, 5))\n",
    "\n",
    "    job_results = Parallel(n_jobs=32, verbose=10)(gen)\n",
    "    \n",
    "    for d in job_results:\n",
    "        ngrams_map.update(d)\n",
    "        \n",
    "    with open('ngrams.json', 'w') as f:\n",
    "        json.dump(ngrams_map, f)\n",
    "\n",
    "parallel_collect(all_sents, ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def extract_ngram_freqs(doc):\n",
    "    feats = {}\n",
    "    \n",
    "    toks = tokenize(doc)\n",
    "    \n",
    "    feats['avg-1-gram-freq'] = np.mean([sum(get_freqs(gram)) for gram in gen_ngrams(toks, 1)])\n",
    "    \n",
    "    if len(doc) >= 2:\n",
    "        feats['avg-2-gram-freq'] = np.mean([sum(get_freqs(gram)) for gram in gen_ngrams(toks, 2)])\n",
    "    if len(doc) >= 3:\n",
    "        feats['avg-3-gram-freq'] = np.mean([sum(get_freqs(gram)) for gram in gen_ngrams(toks, 3)])\n",
    "    if len(doc) >= 4:\n",
    "        feats['avg-4-gram-freq'] = np.mean([sum(get_freqs(gram)) for gram in gen_ngrams(toks, 4)])\n",
    "    \n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_subj_verb_ngram_freqs(doc):\n",
    "    feats = {}\n",
    "    main = find_main_token(doc)\n",
    "    \n",
    "    if main.pos_ == 'VERB':\n",
    "        subj = None\n",
    "        for tok in doc:\n",
    "            if tok.head.dep_ == 'ROOT' and tok.dep_ == 'nsubj':\n",
    "                subj = tok\n",
    "                break\n",
    "        if subj:\n",
    "            feats['subj-verb-freq'] = sum(get_or_fetch_freqs([subj.text, main.text]))\n",
    "\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## На самих н-грамах якість поганенька, а LRC взагалі видавала нулі, що в принципі очікувано (нормалізація не помагала)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oleh:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       0.50      0.16      0.24        75\n",
      "        tell       0.74      0.94      0.83       189\n",
      "\n",
      "    accuracy                           0.72       264\n",
      "   macro avg       0.62      0.55      0.53       264\n",
      "weighted avg       0.67      0.72      0.66       264\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Scraped:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       1.00      0.07      0.14        40\n",
      "        tell       0.41      1.00      0.58        26\n",
      "\n",
      "    accuracy                           0.44        66\n",
      "   macro avg       0.71      0.54      0.36        66\n",
      "weighted avg       0.77      0.44      0.31        66\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Katia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       0.12      0.13      0.13        15\n",
      "        tell       0.89      0.88      0.89       118\n",
      "\n",
      "    accuracy                           0.80       133\n",
      "   macro avg       0.51      0.51      0.51       133\n",
      "weighted avg       0.80      0.80      0.80       133\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "All:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       0.40      0.13      0.20       130\n",
      "        tell       0.73      0.92      0.82       333\n",
      "\n",
      "    accuracy                           0.70       463\n",
      "   macro avg       0.56      0.53      0.51       463\n",
      "weighted avg       0.64      0.70      0.64       463\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = make_rfc_classifier(extract_ngram_freqs, extract_subj_verb_ngram_freqs)\n",
    "clf.fit(X_oleh_train, y_oleh_train)\n",
    "validation_report(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Після комбінації з POS i DEP частотами все одно зле"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oleh:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       0.83      0.17      0.29       110\n",
      "        tell       0.71      0.98      0.82       222\n",
      "\n",
      "    accuracy                           0.71       332\n",
      "   macro avg       0.77      0.58      0.55       332\n",
      "weighted avg       0.75      0.71      0.64       332\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Scraped:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       1.00      0.05      0.10        40\n",
      "        tell       0.41      1.00      0.58        26\n",
      "\n",
      "    accuracy                           0.42        66\n",
      "   macro avg       0.70      0.53      0.34        66\n",
      "weighted avg       0.77      0.42      0.29        66\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Katia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       0.00      0.00      0.00        15\n",
      "        tell       0.89      0.98      0.93       118\n",
      "\n",
      "    accuracy                           0.87       133\n",
      "   macro avg       0.44      0.49      0.47       133\n",
      "weighted avg       0.79      0.87      0.83       133\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "All:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        show       0.78      0.13      0.22       165\n",
      "        tell       0.71      0.98      0.83       366\n",
      "\n",
      "    accuracy                           0.72       531\n",
      "   macro avg       0.75      0.56      0.52       531\n",
      "weighted avg       0.73      0.72      0.64       531\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = make_rfc_classifier(extract_pos_freqs, extract_dep_freqs, extract_subj_verb, extract_subj_verb_ctx)\n",
    "clf.fit(X_oleh_train, y_oleh_train)\n",
    "validation_report(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Висновки і спостереження:\n",
    "\n",
    "* фічі, з якими я ще експериментував, але які не дали приросту в якості:\n",
    "  * усереднений вектор прикментників;\n",
    "  * конкатенація векторів головного токену і його дітей в дереві залежностей;\n",
    "\n",
    "* схоже на те, що в кожного своє розуміння show i tell речень :)\n",
    "  * я розмічав дані за принципом, якщо є хоча б якесь мінімальне перефразування (she felt fear while walking the corridors -> as she walked through the dark corridors, her heartbeat increased with every step), то це речення я вважав `show`;\n",
    "  * у Каті та на сайтах рекомендацій схоже більш строгі вимоги до show;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word():\n",
    "    def __init__(self,\n",
    "                 wid,\n",
    "                 nlet,\n",
    "                 nphon,\n",
    "                 nsyl,\n",
    "                 kf_freq,\n",
    "                 kf_ncats,\n",
    "                 kf_nsamp,\n",
    "                 tl_freq,\n",
    "                 brown_freq,\n",
    "                 fam,\n",
    "                 conc,\n",
    "                 imag,\n",
    "                 meanc,\n",
    "                 meanp,\n",
    "                 aoa,\n",
    "                 tq2,\n",
    "                 wtype,\n",
    "                 pdwtype,\n",
    "                 alphasyl,\n",
    "                 status,\n",
    "                 var,\n",
    "                 cap,\n",
    "                 irreg,\n",
    "                 word,\n",
    "                 phon,\n",
    "                 dphon,\n",
    "                 stress):\n",
    "        self.wid = wid\n",
    "        self.nlet = nlet\n",
    "        self.nphon = nphon\n",
    "        self.nsyl = nsyl\n",
    "        self.kf_freq = kf_freq\n",
    "        self.kf_ncats = kf_ncats\n",
    "        self.kf_nsamp = kf_nsamp\n",
    "        self.tl_freq = tl_freq\n",
    "        self.brown_freq = brown_freq\n",
    "        self.fam = fam\n",
    "        self.conc = conc\n",
    "        self.imag = imag\n",
    "        self.meanc = meanc\n",
    "        self.meanp = meanp\n",
    "        self.aoa = aoa\n",
    "        self.tq2 = tq2\n",
    "        self.wtype = wtype\n",
    "        self.pdwtype = pdwtype\n",
    "        self.alphasyl = alphasyl\n",
    "        self.status = status\n",
    "        self.var = var\n",
    "        self.cap = cap\n",
    "        self.irreg = irreg\n",
    "        self.word = word\n",
    "        self.phon = phon\n",
    "        self.dphon = dphon\n",
    "        self.stress = stress\n",
    "        \n",
    "    def __repr__(self):\n",
    "        s = \"<Word(\\\n",
    "id: %d\\n\\\n",
    "nlet: %d\\n\\\n",
    "nphon: %d\\n\\\n",
    "nsyl: %d\\n\\\n",
    "kf_freq: %d\\n\\\n",
    "kf_ncats: %d\\n\\\n",
    "kf_nsamp: %d\\n\\\n",
    "tl_freq: %d\\n\\\n",
    "brown_freq: %d\\n\\\n",
    "fam: %d\\n\\\n",
    "conc: %d\\n\\\n",
    "imag: %d\\n\\\n",
    "meanc: %d\\n\\\n",
    "meanp: %d\\n\\\n",
    "aoa: %d\\n\\\n",
    "tq2: %s\\n\\\n",
    "wtype: %s\\n\\\n",
    "pdwtype: %s\\n\\\n",
    "alphasyl: %s\\n\\\n",
    "status: %s\\n\\\n",
    "var: %s\\n\\\n",
    "cap: %s\\n\\\n",
    "irreg: %s\\n\\\n",
    "word: %s\\n\\\n",
    "phon: %s\\n\\\n",
    "dphon: %s\\n\\\n",
    "stress: %s)>\\n\" % (\n",
    "        self.wid,\n",
    "        self.nlet,\n",
    "        self.nphon,\n",
    "        self.nsyl,\n",
    "        self.kf_freq,\n",
    "        self.kf_ncats,\n",
    "        self.kf_nsamp,\n",
    "        self.tl_freq,\n",
    "        self.brown_freq,\n",
    "        self.fam,\n",
    "        self.conc,\n",
    "        self.imag,\n",
    "        self.meanc,\n",
    "        self.meanp,\n",
    "        self.aoa,\n",
    "        self.tq2,\n",
    "        self.wtype,\n",
    "        self.pdwtype,\n",
    "        self.alphasyl,\n",
    "        self.status,\n",
    "        self.var,\n",
    "        self.cap,\n",
    "        self.irreg,\n",
    "        self.word,\n",
    "        self.phon,\n",
    "        self.dphon,\n",
    "        self.stress)\n",
    "\n",
    "        return s       \n",
    "    \n",
    "def parse_mrc(file):\n",
    "    words = {}\n",
    "\n",
    "    i = 0\n",
    "    with open(file, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "\n",
    "            word, phon, dphon, stress = line[51:].split('|')\n",
    "\n",
    "            w = Word(\n",
    "                    wid = i,\n",
    "                    nlet = int(line[0:2]),\n",
    "                    nphon = int(line[2:4]),\n",
    "                    nsyl = int(line[4]),\n",
    "                    kf_freq = int(line[5:10]),\n",
    "                    kf_ncats = int(line[10:12]),\n",
    "                    kf_nsamp = int(line[12:15]),\n",
    "                    tl_freq = int(line[15:21]),\n",
    "                    brown_freq = int(line[21:25]),\n",
    "                    fam = int(line[25:28]),\n",
    "                    conc = int(line[28:31]),\n",
    "                    imag = int(line[31:34]),\n",
    "                    meanc = int(line[34:37]),\n",
    "                    meanp = int(line[37:40]),\n",
    "                    aoa = int(line[40:43]),\n",
    "                    tq2 = line[43],\n",
    "                    wtype = line[44],\n",
    "                    pdwtype = line[45],\n",
    "                    alphasyl = line[46],\n",
    "                    status = line[47],\n",
    "                    var = line[48],\n",
    "                    cap = line[49],\n",
    "                    irreg = line[50],\n",
    "                    word=word,\n",
    "                    phon=phon,\n",
    "                    dphon=dphon,\n",
    "                    stress=stress)\n",
    "\n",
    "            i+=1\n",
    "            if i%1000 == 0:\n",
    "                print(i)\n",
    "            \n",
    "            words[word] = w\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "100000\n",
      "101000\n",
      "102000\n",
      "103000\n",
      "104000\n",
      "105000\n",
      "106000\n",
      "107000\n",
      "108000\n",
      "109000\n",
      "110000\n",
      "111000\n",
      "112000\n",
      "113000\n",
      "114000\n",
      "115000\n",
      "116000\n",
      "117000\n",
      "118000\n",
      "119000\n",
      "120000\n",
      "121000\n",
      "122000\n",
      "123000\n",
      "124000\n",
      "125000\n",
      "126000\n",
      "127000\n",
      "128000\n",
      "129000\n",
      "130000\n",
      "131000\n",
      "132000\n",
      "133000\n",
      "134000\n",
      "135000\n",
      "136000\n",
      "137000\n",
      "138000\n",
      "139000\n",
      "140000\n",
      "141000\n",
      "142000\n",
      "143000\n",
      "144000\n",
      "145000\n",
      "146000\n",
      "147000\n",
      "148000\n",
      "149000\n",
      "150000\n"
     ]
    }
   ],
   "source": [
    "mrc = parse_mrc('mrc2.dct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Word(id: 6692\n",
       "nlet: 10\n",
       "nphon: 0\n",
       "nsyl: 4\n",
       "kf_freq: 125\n",
       "kf_ncats: 15\n",
       "kf_nsamp: 100\n",
       "tl_freq: 355\n",
       "brown_freq: 25\n",
       "fam: 0\n",
       "conc: 0\n",
       "imag: 0\n",
       "meanc: 0\n",
       "meanp: 0\n",
       "aoa: 0\n",
       "tq2:  \n",
       "wtype: A\n",
       "pdwtype:  \n",
       "alphasyl:  \n",
       "status: S\n",
       "var:  \n",
       "cap:  \n",
       "irreg:  \n",
       "word: APPARENTLY\n",
       "phon: \n",
       "dphon: @'p&r@ntlI\n",
       "stress: )>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrc['APPARENTLY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
